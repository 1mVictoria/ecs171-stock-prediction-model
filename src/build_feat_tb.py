#!/usr/bin/env python3
"""
build_feat_tb.py  â€“ Pre-compute the full feature table and pickle it
                   for the Flask web-app (Option 1 workflow).

â€¢ Reads the three cleaned CSVs (prices, fundamentals, ESG)
â€¢ Adds the 9 technical features exactly like train_random_forest.py
â€¢ Keeps the 3 fundamental + 4 ESG columns â†’ 16 total
â€¢ Indexes the result by (symbol, date)   â† critical for fast lookup
â€¢ Writes to  web-interface/static/data/feature_table.pkl
"""

import os
import pickle
import pandas as pd

# Re-use the helpers already defined in train_random_forest.py
from train_random_forest import load_and_merge, compute_rsi

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
FEATURE_COLS = [
    # 9 technical
    "close", "volume",
    "ret_1d", "ret_2d", "momentum_5d",
    "ma_5d", "vol_5d", "accel", "rsi_14",
    # 3 fundamental
    "earnings per share", "total revenue", "net income",
    # 4 ESG
    "total esg risk score", "environment risk score",
    "social risk score", "governance risk score",
]
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€


def build_feature_table():
    base_dir = os.path.dirname(__file__)                     # â€¦/src
    data_dir = os.path.abspath(os.path.join(base_dir, "..", "data_Cleaning", "cleaned"))

    print(f"ğŸ”„  Loading & merging data from: {data_dir}")
    df = load_and_merge(data_dir)                            # symbol, date, â€¦

    # â”€â”€â”€ Technical features (identical to train_random_forest.py) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    grp = df.groupby("symbol")["close"]
    df["ret_1d"]      = grp.pct_change(1)
    df["ret_2d"]      = grp.pct_change(2)
    df["momentum_5d"] = grp.transform(lambda x: x / x.shift(5))
    df["ma_5d"]       = grp.transform(lambda x: x.rolling(5).mean())
    df["vol_5d"]      = grp.transform(lambda x: x.rolling(5).std())
    df["accel"]       = grp.diff().diff()
    df["rsi_14"]      = grp.transform(compute_rsi)

    # â”€â”€â”€ Assemble final table â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    df["symbol"] = df["symbol"].str.upper()                  # force upper-case once
    out_df = (
        df[["symbol", "date"] + FEATURE_COLS]
        .dropna(subset=FEATURE_COLS)   # â† keep rows even if other feats NaN
        .set_index(["symbol", "date"])
        .sort_index()
    )

    # â”€â”€â”€ Write pickle into web-interface/static/data â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    project_root = os.path.abspath(os.path.join(base_dir, ".."))
    out_path     = os.path.join(
        project_root, "web-interface", "static", "data", "feature_table.pkl"
    )
    os.makedirs(os.path.dirname(out_path), exist_ok=True)

    with open(out_path, "wb") as f:
        pickle.dump(out_df, f)

    print(f"âœ…  Wrote feature table {out_df.shape} â†’ {out_path}")


if __name__ == "__main__":
    build_feature_table()
